import re
import difflib
from pathlib import Path
from collections import defaultdict
from typing import List, Tuple, Optional, Set

class TweeL10nValidator:
    """
    .twee íŒŒì¼ì˜ ì›ë³¸ê³¼ ë²ˆì—­ë³¸ì„ ë¹„êµí•˜ì—¬ ë¡œì»¬ë¼ì´ì œì´ì…˜ í’ˆì§ˆì„ ê²€ì¦í•˜ëŠ” ì¢…í•© í´ë˜ìŠ¤.
    1ë‹¨ê³„(êµ¬ì¡°)ì™€ 2ë‹¨ê³„(êµ¬ë¬¸) ê²€ì‚¬ë¥¼ í¬í•¨í•˜ë©°, í™•ì¥ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
    """

    # ë¯¸ë¦¬ ì»´íŒŒì¼ëœ ì •ê·œí‘œí˜„ì‹
    REGEX = {
        "passage_header": re.compile(r"^(::\s.*)$"),
        "macro": re.compile(r"<<.*?>>"),
        "variable": re.compile(r"\$[a-zA-Z0-9_.]+"),
        "link_with_dest": re.compile(r"\[\[(.*?)\|(.*?)\]\]"),
        "link_simple": re.compile(r"\[\[([^|]+?)\]\]"),
        "string_literal": re.compile(r'["\'](.*?)["\']'),
        "korean": re.compile(r"[ê°€-í£]"),
    }
    
    def __init__(self, original_path: Path, translated_path: Path):
        self.original_path = original_path
        self.translated_path = translated_path
        self.issues = []

        try:
            self.original_lines = self.original_path.read_text('utf-8').splitlines()
            self.translated_lines = self.translated_path.read_text('utf-8').splitlines()
        except FileNotFoundError as e:
            print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {e}")
            exit(1)

    def _add_issue(self, **kwargs):
        """ê²€ì¦ëœ ë¬¸ì œë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        self.issues.append(kwargs)

    def run_validation_pipeline(self):
        """ëª¨ë“  ê²€ì¦ ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("1ë‹¨ê³„: êµ¬ì¡°ì  ë¬´ê²°ì„± ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        is_structure_ok = self._check_line_count_and_structure()

        print("\n2.1ë‹¨ê³„: ì½”ë“œ ì˜¤ì—¼ ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        self._check_global_variable_consistency()
        self._check_macro_corruption()
        
        # 3ë²ˆ ìš”êµ¬ì‚¬í•­ ë°˜ì˜: ì „ì—­ ê²€ì‚¬ì™€ ë³„ê°œë¡œ ë¼ì¸ë³„ ë³€ìˆ˜ ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•˜ì—¬ ëª¨ë“  ì˜¤ë¥˜ ìœ„ì¹˜ë¥¼ ê¸°ë¡
        if is_structure_ok:
            self._check_line_by_line_variable_consistency()
        else:
            print("\nê²½ê³ : íŒŒì¼ êµ¬ì¡°ê°€ ë‹¬ë¼ ë¼ì¸ë³„ ë³€ìˆ˜ ê²€ì‚¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. êµ¬ì¡°ë¥¼ ë¨¼ì € ìˆ˜ì •í•˜ì„¸ìš”.")

        print(f"\nëª¨ë“  ê²€ì¦ ì™„ë£Œ. ì´ {len(self.issues)}ê°œì˜ ë¬¸ì œ ë°œê²¬.")

    def _check_line_count_and_structure(self) -> bool:
        """íŒŒì¼ì˜ ì´ ì¤„ ìˆ˜ì™€ êµ¬ì¡°ì  ì°¨ì´ë¥¼ ìƒì„¸íˆ ê²€ì‚¬í•©ë‹ˆë‹¤."""
        if len(self.original_lines) == len(self.translated_lines):
            return True

        self._add_issue(
            line_num=0, severity="CRITICAL", type="êµ¬ì¡°ì  ì˜¤ë¥˜",
            description=f"íŒŒì¼ì˜ ì „ì²´ ì¤„ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì›ë³¸: {len(self.original_lines)}ì¤„, ë²ˆì—­ë³¸: {len(self.translated_lines)}ì¤„)"
        )

        matcher = difflib.SequenceMatcher(None, self.original_lines, self.translated_lines, autojunk=False)
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'equal':
                continue
            
            if tag == 'delete' or tag == 'insert':
                description = f"ì›ë³¸ {i1+1}ë²ˆì§¸ ì¤„ ê·¼ì²˜ì—ì„œ ì¤„ì´ ì‚­ì œ/ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì›ë³¸ê³¼ êµ¬ì¡°ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤."
                diff_lines = []
                # Context (Before)
                start = max(0, i1 - 2)
                for i in range(start, i1): diff_lines.append(f"  {self.original_lines[i]}")
                # Deleted lines
                for i in range(i1, i2): diff_lines.append(f"- {self.original_lines[i]}")
                # Inserted lines
                for j in range(j1, j2): diff_lines.append(f"+ {self.translated_lines[j]}")
                # Context (After)
                end = min(len(self.original_lines), i2 + 2)
                for i in range(i2, end): diff_lines.append(f"  {self.original_lines[i]}")

                self._add_issue(
                    line_num=i1 + 1, severity="CRITICAL", type="êµ¬ì¡°ì  ë¶ˆì¼ì¹˜ (ì¤„ ì‚­ì œ/ì¶”ê°€)",
                    description=description, diff_text="\n".join(diff_lines)
                )
        return False

    def _check_global_variable_consistency(self):
        """[ì „ì—­ ê²€ì‚¬] íŒŒì¼ ì „ì²´ì˜ ë³€ìˆ˜ ëª©ë¡ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        original_vars = set(self.REGEX["variable"].findall("\n".join(self.original_lines)))
        translated_vars = set(self.REGEX["variable"].findall("\n".join(self.translated_lines)))

        missing = original_vars - translated_vars
        added = translated_vars - original_vars

        if missing:
            self._add_issue(
                severity="CRITICAL", type="[ì „ì—­] ë³€ìˆ˜ ëˆ„ë½",
                description=f"ë‹¤ìŒ ë³€ìˆ˜ë“¤ì´ ë²ˆì—­ë³¸ ì „ì²´ì—ì„œ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(sorted(list(missing)))}",
                line_num=0
            )
        if added:
            self._add_issue(
                severity="CRITICAL", type="[ì „ì—­] ë³€ìˆ˜ ì†ìƒ/ì¶”ê°€",
                description=f"ë‹¤ìŒ ë³€ìˆ˜ë“¤ì´ ì˜ëª» ì¶”ê°€/ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(sorted(list(added)))}",
                line_num=0
            )

    def _check_line_by_line_variable_consistency(self):
        """[ë¼ì¸ë³„ ê²€ì‚¬] ê° ë¼ì¸ì˜ ë³€ìˆ˜ ëª©ë¡ì´ ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        for i, (original_line, translated_line) in enumerate(zip(self.original_lines, self.translated_lines)):
            orig_vars = set(self.REGEX["variable"].findall(original_line))
            trans_vars = set(self.REGEX["variable"].findall(translated_line))

            if orig_vars != trans_vars:
                missing = orig_vars - trans_vars
                added = trans_vars - orig_vars
                desc = "í•´ë‹¹ ë¼ì¸ì˜ ë³€ìˆ˜ ëª©ë¡ì´ ì›ë³¸ê³¼ ë‹¤ë¦…ë‹ˆë‹¤."
                if missing: desc += f" (ëˆ„ë½: {', '.join(missing)})"
                if added: desc += f" (ì¶”ê°€/ì†ìƒ: {', '.join(added)})"
                
                self._add_issue(
                    severity="CRITICAL", type="[ë¼ì¸ë³„] ë³€ìˆ˜ ë¶ˆì¼ì¹˜",
                    description=desc, line_num=i + 1,
                    original=original_line, translated=translated_line
                )

    def _check_macro_corruption(self):
        """ë§¤í¬ë¡œ ë‚´ë¶€ì— í•œêµ­ì–´ ë¬¸ìì—´ ë¦¬í„°ëŸ´ì´ ìˆëŠ”ì§€ ê²€ì‚¬í•©ë‹ˆë‹¤."""
        for i, translated_line in enumerate(self.translated_lines):
            translated_macros = self.REGEX["macro"].findall(translated_line)
            for trans_macro in translated_macros:
                literals = self.REGEX["string_literal"].findall(trans_macro)
                for literal in literals:
                    # 4ë²ˆ ìš”êµ¬ì‚¬í•­ ë°˜ì˜: ë§¤í¬ë¡œ ë‚´ë¶€ì— ì–´ë–¤ í˜•íƒœì˜ í•œêµ­ì–´ë“  ë°œê²¬ë˜ë©´ ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
                    if self.REGEX["korean"].search(literal):
                        self._add_issue(
                            severity="CRITICAL", type="ë§¤í¬ë¡œ ì½”ë“œ ì†ìƒ",
                            description=f"ë§¤í¬ë¡œ ë‚´ë¶€ ì½”ë“œì— í•œêµ­ì–´('{literal}')ê°€ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ê²Œì„ ì˜¤ë¥˜ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. EasyPost í˜•ì‹(`<<..._nun>>`)ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.",
                            line_num=i + 1,
                            original=f"ì›ë³¸ ë¼ì¸: `{self.original_lines[i]}`" if i < len(self.original_lines) else "ì›ë³¸ ë¼ì¸ ì—†ìŒ",
                            translated=f"ë²ˆì—­ ë¼ì¸: `{translated_line}`"
                        )
                        break # í•œ ë§¤í¬ë¡œì—ì„œ ì—¬ëŸ¬ ì˜¤ë¥˜ê°€ ìˆì–´ë„ í•˜ë‚˜ë§Œ ë³´ê³ 

    def generate_report(self, output_path: Path):
        """ê²€ì¦ ê²°ê³¼ë¥¼ Markdown íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
        report_content = f"# â— ì¢…í•© ê²€ì¦ ë¦¬í¬íŠ¸: {self.translated_path.name}\n\n"
        if not self.issues:
            report_content += "## âœ… ê²€ì¦ ì™„ë£Œ: ë°œê²¬ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤."
        else:
            severity_order = {"CRITICAL": 0, "WARNING": 1, "INFO": 2}
            sorted_issues = sorted(self.issues, key=lambda x: (x["line_num"], severity_order.get(x["severity"], 99)))
            
            summary = defaultdict(int)
            for issue in self.issues: summary[issue["severity"]] += 1

            report_content += f"## ìš”ì•½\n\n- **ì´ ë¬¸ì œ ìˆ˜: {len(self.issues)}**\n"
            if summary["CRITICAL"] > 0: report_content += f"- ğŸ”´ **ì¹˜ëª…ì  ì˜¤ë¥˜ (CRITICAL): {summary['CRITICAL']}**\n"
            
            report_content += "\n---\n\n## ìƒì„¸ ë‚´ìš©\n\n"

            for issue in sorted_issues:
                severity_icon = "ğŸ”´"
                report_content += f"### {severity_icon} [{issue['severity']}] {issue['type']} (ì›ë³¸ ê¸°ì¤€ Line: {issue['line_num'] or 'ì „ì—­'})\n\n"
                report_content += f"- **ë¬¸ì œ ì„¤ëª…:** {issue['description']}\n"
                if issue.get('diff_text'):
                    report_content += f"**ì°¨ì´ì  ë¶„ì„ (Diff):**\n```diff\n{issue['diff_text']}\n```\n"
                if issue.get('original'):
                    report_content += f"- **ì›ë³¸:** `{issue['original']}`\n"
                if issue.get('translated'):
                    report_content += f"- **ë²ˆì—­ë³¸:** `{issue['translated']}`\n"
                report_content += "\n---\n"
        
        output_path.write_text(report_content, 'utf-8')
        print(f"ë¦¬í¬íŠ¸ê°€ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # --- ì„¤ì •: ì—¬ê¸°ì— ê²€ì¦í•  íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”. ---
    ORIGINAL_FILE_PATH =
    TRANSLATED_FILE_PATH =
    OUTPUT_REPORT_PATH =
    # ----------------------------------------------------

    original_p = Path(ORIGINAL_FILE_PATH)
    translated_p = Path(TRANSLATED_FILE_PATH)
    output_p = Path(OUTPUT_REPORT_PATH)

    validator = TweeL10nValidator(original_path=original_p, translated_path=translated_p)
    validator.run_validation_pipeline()
    validator.generate_report(output_path=output_p)
